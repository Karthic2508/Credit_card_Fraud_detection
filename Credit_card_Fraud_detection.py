# -*- coding: utf-8 -*-
"""DAV_final_package.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RCPehwesc4GKgDrH9fD3zbJKUbm3ZQbv

**OBJECTIVE**

To build a model that detects credit card fraud.

**IMPORT REQUIRED LIBRARIES**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly
from plotly import tools
import plotly.express as px
sns.set_style("darkgrid", {"grid.color": ".2", "grid.linestyle": ":"})

from sklearn.linear_model import LogisticRegression

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split, KFold

from sklearn.tree import DecisionTreeClassifier

import warnings
warnings.filterwarnings('ignore')

"""**READING DATA**"""

#reading data
df = pd.read_csv('/content/drive/MyDrive/creditcard.csv')
df

"""**EXPLARATORY DATA ANALYSIS**"""

df.Class.value_counts()

df.info()

pip install dataprep

from dataprep import eda

report = eda.create_report(df)
report

"""Plot the histogram of a variable from the dataset to see the skewness."""

normal_records = df.Class == 0
fraud_records = df.Class == 1

plt.figure(figsize=(20, 60))
for n, col in enumerate(df.drop('Class',axis=1).columns):
    plt.subplot(10,3,n+1)
    sns.histplot(df[col][df.Class == 1], bins=50)
    sns.histplot(df[col][df.Class == 0], bins=50)
    plt.title(col, fontsize=17)
plt.show()

df[['Time','Amount','Class']].groupby('Class').describe()

"""Looks like there is clear relationship between amount and Class.

Average of amount is low for the fraudelant transactions. Lets Do further analysis to understand more.
"""

df.boxplot('Amount')

df[df.Class == 0].plot.scatter('Amount','Time')
df[df.Class == 1].plot.scatter('Amount','Time')

df[df.Amount > 10000].shape

"""There are 7 record in dataset the Amount is greater than 10,000.00, with scatterplot we can see all of these transactions are belongs to non-fraudelent as well.

"""

df = df.drop(df[df.Amount > 10000].index, axis=0)

df.boxplot('Time')

x = df.drop('Class', axis=1)
y = df.Class.values

corr_matrix = x.corr()
plt.figure(figsize=(30,30))
sns.heatmap(corr_matrix, annot = True)
plt.show()

"""Handling imbalance data."""

counts = df.Class.value_counts()
print(counts)
print(f'legimate {(counts[0] / sum(counts))*100}% and Fraudent {(counts[1] / sum(counts))*100}%')

"""**Summary of EDA**


*   Data looks clean
*   No null values


*   Majority of features are well distributed around mean
*   There are some correlated features. but not strong enough to drop


*   Dataset is highly imbalanced.

**Resampling stratergy**

Dataset is highly imbalanced. Fraudulent transactions are only 0.17% from entire dataset. Direct oversampling or under sampling will not work for the dataset. Let's do mix of oversampling and under sampling to cover more data points from none-fraudulent than taking just 492 records out of 284308 samples.

Lets take random 5% from non-fraudulent transactions
Then will oversample fraudulent transactions to match with non-fraudulent
"""

# Since dataset is highly unbalanced we can use under sampling or mix of under and over sampling to increase number of samples
leg_df = df[df.Class == 0]
fraud_df = df[df.Class == 1]

no_of_samples = round(leg_df.shape[0] * 0.05)
no_of_samples

from imblearn.over_sampling import RandomOverSampler
from sklearn.utils import resample

leg_df_2 = resample(leg_df, n_samples=no_of_samples, random_state=15)
# leg_df_2.describe()
df_sampled = pd.concat([leg_df_2,fraud_df],axis=0)

x_sampled = df_sampled.drop('Class', axis=1)
y_sampled = df_sampled.Class

ros = RandomOverSampler(random_state=42)

x,y = ros.fit_resample(x_sampled,y_sampled)

y.value_counts()

x_train,x_test,y_train,y_test = train_test_split(x,y, stratify=y, random_state=12)
y_train.value_counts(), y_test.value_counts()

"""**Defining Evaluation criteria**"""

columns = ['Model','accuracy score', ' Precision','Recall','f1_score']
evaluation_df = pd.DataFrame(columns=columns)
evaluation_df

import sklearn.metrics as metrics

def print_results(model_name, y_test, y_pred, pred_prob=None):
    print(model_name)
    print('--------------------------------------------------------------------------')
 
    precision_score = metrics.precision_score(y_test, y_pred)
    recall_score = metrics.recall_score(y_test, y_pred)
    
    accuracy_score  = metrics.accuracy_score(y_test,y_pred)
    print(f'accuracy score :{accuracy_score}') 

    f1_score = metrics.f1_score(y_test,y_pred)
    
    classification_report = metrics.classification_report(y_test,y_pred)
    print(classification_report)
    
#   save scores into dataframe for comparison
    evaluation_df.loc[len(evaluation_df.index)] = [model_name,accuracy_score,precision_score,recall_score, f1_score]
    
    Plot_confusion_matrix(y_test,y_pred,model_name)
    
    if pred_prob is not None:
        Plot_roc_curve(y_test,pred_prob,model_name,accuracy_score)

# Created a common function to plot confusion matrix
def Plot_confusion_matrix(y, pred, model_name):
    cm = metrics.confusion_matrix(y, pred)
    plt.clf()
    plt.imshow(cm, cmap=plt.cm.Accent)
    categoryNames = ['Non-Fraudulent','Fraudulent']
    plt.title(f'Confusion Matrix - {model_name}')
    plt.ylabel('True labels')
    plt.xlabel('Predicted labels')
    ticks = np.arange(len(categoryNames))
    plt.xticks(ticks, categoryNames, rotation=45)
    plt.yticks(ticks, categoryNames)
    s = [['TN','FP'], ['FN', 'TP']]

    for i in range(2):
        for j in range(2):
            plt.text(j,i, str(s[i][j])+" = "+str(cm[i][j]),fontsize=12)
    plt.show()

def Plot_roc_curve(y, y_prob, model_name, score):
    plt.title(f'ROC Curve - {model_name}')
    fpr, tpr, thresholds = metrics.roc_curve(y, y_prob)
    plt.plot(fpr,tpr,label="Test, auc="+str(score))
    plt.legend(loc=4)
    plt.show()

"""**Applying the Decision Tree classifier without downsampling the data**"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

"""First let's scale the data since most of the data in Amount and Time is very large compared to the other ones and it can heavily influence the classifier. 

We will use scikitlearn's standard scaler.
"""

scale=StandardScaler()

amount=df['Amount'].to_numpy() 
#standard scaler only takes one dimensional arrays
df['Amount']=scale.fit_transform(amount.reshape(-1,1))

time=df['Time'].to_numpy()
df['Time']=scale.fit_transform(time.reshape(-1,1))

#divide the data into a set of feature values and target values
X_data=df.iloc[:,:30]
y_data=df['Class']

"""train_test_split will split the data into train and test sets randomly"""

X_train,X_test,y_train,y_test=train_test_split(X_data,y_data)

from sklearn.tree import DecisionTreeClassifier
clf=DecisionTreeClassifier(max_depth=20)
clf.fit(X_train,y_train)

"""Let's Check our accuracy score."""

clf.score(X_test,y_test)

"""Accuracy is not enough

If we only go by the accuracy score it is easy to trick the model since we could have also gotten it by just putting the prections as zeros .i.e. there were no frauds and easily get a better score since most of the data belongs to the 'normal transactions' categories. 

So what we can do here is use the recall score to get a better intuition on how the model performs.
"""

predicted_yval=clf.predict(X_test)

"""Why Recall?

If we want to detect fraud in a transaction, It is more efficient to capture more fraud even if we capture a few good transactions with them atleast the system would catch 9/10 or 10/10 frauds transactions in the process
"""

from sklearn.metrics import precision_score
from sklearn.metrics import recall_score

print('precision :{}'.format(precision_score(y_test,predicted_yval)))
print('recall: {}'.format(recall_score(y_test,predicted_yval)))

from sklearn.metrics import f1_score

f1_score(y_test,predicted_yval)

#function to get the number of fraud transactions that evaded the system
def get_frauds_not_detected(ytrue,predictions):
    wrong_calculations= ytrue[ytrue!=predictions]
    return wrong_calculations[wrong_calculations==1].shape[0]

print('total_frauds {}'.format(y_test[y_test==1].shape[0]))

"""Doing some Downsampling

In the last attempt at creating a fraud detection system, the data was imbalanced. 

There was a greater representation of a data from a particular class than the other hence we make another attempt by selecting all the fraud cases and same number of normal cases to try to get a better recall.
"""

no_fraud_data=df[df['Class']==0]

fraud_data=df[df['Class']==1]

total_frauds=fraud_data.shape[0]
#for downsampling we will need to select the set of data that are not too large than that frauds

no_fraud_indices=np.random.choice(no_fraud_data.index,total_frauds,replace=False)
fraud_indices=fraud_data.index

under_sampled_data=df.iloc[list(no_fraud_indices)+list(fraud_indices)]

under_sampled_data[under_sampled_data['Class']==1]

X_train,X_test,y_train,y_test=train_test_split(under_sampled_data.iloc[:,:30],
                                               under_sampled_data['Class'])

"""**Logistic Regression**"""

lr_model = LogisticRegression(max_iter=200,random_state=12)
lr_model.fit(X_train,y_train)
pred1 = lr_model.predict(X_test)
prob1 = lr_model.predict_proba(X_test)
print_results("Logistic Regression", y_test, pred1,prob1[:,-1])

"""**Logistic Regression CV**"""

from sklearn.linear_model import LogisticRegressionCV

cv_num = KFold(n_splits=10, shuffle=True, random_state=12)
lr_modelCV = LogisticRegressionCV(max_iter=200,penalty='l2',scoring='roc_auc',cv=cv_num,tol=10,random_state=12)
lr_modelCV.fit(X_train,y_train)
pred2 = lr_modelCV.predict(X_test)
prob2 = lr_modelCV.predict_proba(X_test)
print_results("Logistic Regression CV", y_test, pred2,prob2[:,-1])

evaluation_df

"""**Using Decision Tree**"""

accuracy=[]
recall_scores=[]
max_depths=[2,4,6,8,10,12,14]
for n in max_depths:
    clf_u=DecisionTreeClassifier(max_depth=n)
    clf_u.fit(X_train,y_train)
    predict=clf_u.predict(X_test)
    recall_scores.append(recall_score(y_test,predict))
    accuracy.append(clf_u.score(X_test,y_test))

fig,(ax1,ax2)=plt.subplots(1,2,figsize=(12,5))

figs=[ax1,ax2]

def plot_graphs(fig_index,y,y_label,X=max_depths):
    global figs
    figs[fig_index].plot(X,y)
    figs[fig_index].set_ylabel(y_label)

# plot_graph(np.arange(7),accuracy)
plot_graphs(1,accuracy,'accuracy')
plot_graphs(0,recall_scores,'recall')

"""We select the parameter that results in a greater recall."""

#training the decison tree classifier with the max depth that has the maximum recall
max_depth=max_depths[recall_scores.index(max(recall_scores))]
clf_u=DecisionTreeClassifier(max_depth=max_depth)
clf_u.fit(X_train,y_train)
predict=clf_u.predict(X_test)
recall_score(y_test,predict)

print('max_depth with maximum recall  {}'.format(max_depth))

import sklearn
plt.figure(figsize=(20,8))
sklearn.tree.plot_tree(clf_u,max_depth=2);

evaluation_df